{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine doesn't grow on trees!\n",
    "\n",
    "Instead of predicting a continuous variable, like price, I'm going to instead shift gears and see if it is possible to predict whether a wine is expensive or not based on its features. For the purposes of this project, I'm going to define expensive as whether or not the wine is priced greater than $100, as this seems like a lot to spend on a bottle. I'm going to begin by running a decision tree as they're intuitive to understand and tweak it as necessary to improve the accuracy and recall metrics. I'll be looking at the accuracy and recall metrics in particular, and will be running a 10-fold cross-validation to ensure the stability of the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "cab_df2 = pd.read_csv('./cablist4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new target variable based on price\n",
    "#$100 seems like a lot to spend on a bottle of wine, so that will be my threshold\n",
    "\n",
    "cab_df2['HighPrice_Ind'] = cab_df2['PriceRetail'].apply(lambda x: 1 if x >= 100.00 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Vintage', 'RatingScore', 'UnqWordInd', 'Attribute_94+ Rated Wine', \\\n",
    "            'Attribute_Boutique Wines', 'Attribute_Business Gifts',\\\n",
    "            'Attribute_Collectible Wines', 'Attribute_Earthy &amp; Spicy', 'Attribute_Great Bottles to Give',\\\n",
    "            'Attribute_Green Wines', 'Attribute_Kosher Wines', 'Attribute_Older Vintages', \\\n",
    "            'Attribute_Private Cellar List', 'Attribute_Rich &amp; Creamy', 'Attribute_Screw Cap Wines', \\\n",
    "            'Attribute_Smooth &amp; Supple', 'Region_California', 'Region_Italy', 'Region_South Africa',\\\n",
    "            'Region_South America', 'Region_Spain', 'Region_Washington']\n",
    "target = ['HighPrice_Ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cab_df2[features]\n",
    "y = cab_df2.HighPrice_Ind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, min_samples_leaf=20, random_state=39)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "treeclf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            feature  importance\n",
       "0                           Vintage    0.105209\n",
       "1                       RatingScore    0.687225\n",
       "2                        UnqWordInd    0.000000\n",
       "3          Attribute_94+ Rated Wine    0.000000\n",
       "4          Attribute_Boutique Wines    0.000000\n",
       "5          Attribute_Business Gifts    0.000000\n",
       "6       Attribute_Collectible Wines    0.000000\n",
       "7      Attribute_Earthy &amp; Spicy    0.000000\n",
       "8   Attribute_Great Bottles to Give    0.000000\n",
       "9             Attribute_Green Wines    0.000000\n",
       "10           Attribute_Kosher Wines    0.000000\n",
       "11         Attribute_Older Vintages    0.000000\n",
       "12    Attribute_Private Cellar List    0.000000\n",
       "13      Attribute_Rich &amp; Creamy    0.000000\n",
       "14        Attribute_Screw Cap Wines    0.000000\n",
       "15    Attribute_Smooth &amp; Supple    0.000000\n",
       "16                Region_California    0.207565\n",
       "17                     Region_Italy    0.000000\n",
       "18              Region_South Africa    0.000000\n",
       "19             Region_South America    0.000000\n",
       "20                     Region_Spain    0.000000\n",
       "21                Region_Washington    0.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Vintage</td>\n      <td>0.105209</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RatingScore</td>\n      <td>0.687225</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>UnqWordInd</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Attribute_94+ Rated Wine</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Attribute_Boutique Wines</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Attribute_Business Gifts</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Attribute_Collectible Wines</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Attribute_Earthy &amp;amp; Spicy</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Attribute_Great Bottles to Give</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Attribute_Green Wines</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Attribute_Kosher Wines</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Attribute_Older Vintages</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Attribute_Private Cellar List</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Attribute_Rich &amp;amp; Creamy</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Attribute_Screw Cap Wines</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Attribute_Smooth &amp;amp; Supple</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Region_California</td>\n      <td>0.207565</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Region_Italy</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Region_South Africa</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Region_South America</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Region_Spain</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Region_Washington</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pd.DataFrame({'feature':features, 'importance':treeclf.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model seems to do a decent job predicting which wines are high priced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Testing Results \n\n\n                 precision    recall  f1-score   support\n\nnot high priced       0.82      0.84      0.83       560\n    high priced       0.73      0.71      0.72       344\n\n       accuracy                           0.79       904\n      macro avg       0.78      0.77      0.77       904\n   weighted avg       0.79      0.79      0.79       904\n\nConfusion Matrix is:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[470,  90],\n",
       "       [101, 243]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds = treeclf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y_test, preds,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately it isn't stable, as the cross-validation shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall Score Summary:\n[1.         0.92929293 0.92929293 0.91919192 0.         0.68686869\n 0.26262626 0.         0.05050505 0.        ]\n0.47777777777777775\nAccuracy Score Summary:\n[0.36131387 0.50364964 0.56569343 0.47810219 0.63868613 0.72627737\n 0.66423358 0.63868613 0.65693431 0.63736264]\n0.5870939279698405\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "recall_scores = cross_val_score(treeclf, x, y, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(treeclf, x, y, cv=10, scoring='accuracy')\n",
    "print (\"Recall Score Summary:\")\n",
    "print (recall_scores)\n",
    "print (recall_scores.mean())\n",
    "\n",
    "print (\"Accuracy Score Summary:\")\n",
    "print (accuracy_scores)\n",
    "print (accuracy_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's restrict features in hopes of improving stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features2 = ['RatingScore','Region_California',\\\n",
    "            'Vintage']\n",
    "target = ['PriceRetail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Testing Results \n\n\n                 precision    recall  f1-score   support\n\nnot high priced       0.82      0.84      0.83       560\n    high priced       0.73      0.71      0.72       344\n\n       accuracy                           0.79       904\n      macro avg       0.78      0.77      0.77       904\n   weighted avg       0.79      0.79      0.79       904\n\nConfusion Matrix is:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[470,  90],\n",
       "       [101, 243]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "x2 = cab_df2[features2]\n",
    "y2 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "treeclf.fit(x2, y2)\n",
    "\n",
    "pred2 = treeclf.predict(x2_test)\n",
    "cm = confusion_matrix(y2_test, pred2)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y2_test, pred2,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall Score Summary:\n[1.         0.92929293 0.92929293 0.91919192 0.         0.62626263\n 0.26262626 0.         0.05050505 0.        ]\n0.4717171717171717\nAccuracy Score Summary:\n[0.36131387 0.50364964 0.56569343 0.47810219 0.63868613 0.76277372\n 0.66423358 0.63868613 0.65693431 0.63736264]\n0.5907435630063368\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(treeclf, x2, y2, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(treeclf, x2, y2, cv=10, scoring='accuracy')\n",
    "print (\"Recall Score Summary:\")\n",
    "print (recall_scores)\n",
    "print (recall_scores.mean())\n",
    "\n",
    "print (\"Accuracy Score Summary:\")\n",
    "print (accuracy_scores)\n",
    "print (accuracy_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6dafacab6bca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'importance'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtreeclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'feature':features, 'importance':treeclf.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A forest may be better than the tree -- Trying a random forest to improve results\n",
    "I'm not that satisfied with the classification tree output, so I'm going to try some random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Testing Results \n\n\n                 precision    recall  f1-score   support\n\nnot high priced       0.78      0.92      0.84       560\n    high priced       0.81      0.57      0.67       344\n\n       accuracy                           0.79       904\n      macro avg       0.79      0.75      0.76       904\n   weighted avg       0.79      0.79      0.78       904\n\nConfusion Matrix is:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[514,  46],\n",
       "       [147, 197]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "x3 = cab_df2[features]\n",
    "y3 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "rfc.fit(x3, y3)\n",
    "\n",
    "pred3 = rfc.predict(x3_test)\n",
    "cm = confusion_matrix(y3_test, pred3)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y3_test, pred3,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall Score Summary:\n[1.         0.86868687 0.64646465 0.47474747 0.06060606 0.33333333\n 0.03030303 0.07070707 0.02020202 0.02020202]\n0.3525252525252526\nAccuracy Score Summary:\n[0.38321168 0.70437956 0.73722628 0.62773723 0.66058394 0.74452555\n 0.64963504 0.66423358 0.63868613 0.64468864]\n0.6454907622790834\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(rfc, x3, y3, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(rfc, x3, y3, cv=10, scoring='accuracy')\n",
    "print (\"Recall Score Summary:\")\n",
    "print (recall_scores)\n",
    "print (recall_scores.mean())\n",
    "\n",
    "print (\"Accuracy Score Summary:\")\n",
    "print (accuracy_scores)\n",
    "print (accuracy_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Gradient Boost this wine!\n",
    "The random forest barely improved the results, and I'd like to try to do better, so I'm going to give Gradient Boosting a try. The logic behind this is that this algorithm will generate a sequence of models that build upon themselves to correct their mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Testing Results \n\n\n                 precision    recall  f1-score   support\n\nnot high priced       0.84      0.89      0.86       560\n    high priced       0.79      0.72      0.75       344\n\n       accuracy                           0.82       904\n      macro avg       0.81      0.80      0.81       904\n   weighted avg       0.82      0.82      0.82       904\n\nConfusion Matrix is:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[496,  64],\n",
       "       [ 98, 246]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "x3 = cab_df2[features]\n",
    "y3 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "gbc.fit(x3, y3)\n",
    "\n",
    "pred3 = gbc.predict(x3_test)\n",
    "cm = confusion_matrix(y3_test, pred3)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y3_test, pred3,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall Score Summary:\n[1.         0.67676768 0.81818182 0.74747475 0.64646465 0.48484848\n 0.21212121 0.19191919 0.14141414 0.02020202]\n0.49393939393939396\nAccuracy Score Summary:\n[0.4379562  0.47080292 0.72627737 0.55474453 0.8649635  0.7080292\n 0.55474453 0.7080292  0.64963504 0.64468864]\n0.631987112644047\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(gbc, x3, y3, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(gbc, x3, y3, cv=10, scoring='accuracy')\n",
    "print (\"Recall Score Summary:\")\n",
    "print (recall_scores)\n",
    "print (recall_scores.mean())\n",
    "\n",
    "print (\"Accuracy Score Summary:\")\n",
    "print (accuracy_scores)\n",
    "print (accuracy_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion:\n",
    "\n",
    "The decision tree models did a mediocre job of predicting whether or not a bottle of wine will be priced above $100. While the recall and accuracy were decent for a single iteration of the model, their stability across multiple iterations was challenged and produced sub-optimal results. I think this can be improved, so I'm going to try some new modeling techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "bec5ec4e689d646587a10d8f49673346de535cdca0b439b938047205f8a48416"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}